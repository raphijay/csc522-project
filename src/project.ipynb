{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CSC 522 Project \n",
    "_by Team 21: Raphael Phillips (rjphill4), Sogolsadat Mansouri (smansou2), Rithik Jain (rjain25), and Neeloy Gomes (ntgomes)_\n",
    "\n",
    "This project will involve developing a machine learning model using supervised learning to predict future exchange rates for a specific currency pair, based on historical exchange rate data and other relevant features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiated the input CSVs as dataframes\n",
      "Cleaned 1448456 rows from data/forex.csv\n",
      "Cleaned 52 rows from data/USDINRX.csv\n"
     ]
    }
   ],
   "source": [
    "%run pre_processing.py\n",
    "\n",
    "usdinr_df = pd.read_csv('../data/USDINRX.csv')\n",
    "forex_df = pd.read_csv('../data/forex.csv')\n",
    "\n",
    "print('Instantiated the input CSVs as dataframes')\n",
    "\n",
    "cleaned_usdinr_df = pre_p_usdinr(usdinr_df)\n",
    "cleaned_forex_df = pre_p_forex(forex_df)\n",
    "\n",
    "print('Cleaned ' + str(len(forex_df.index) - len(cleaned_forex_df.index)) + ' rows from data/forex.csv')\n",
    "print('Cleaned ' + str(len(usdinr_df.index) - len(cleaned_usdinr_df.index)) + ' rows from data/USDINRX.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged the two datasets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12387</td>\n",
       "      <td>45.709000</td>\n",
       "      <td>45.728001</td>\n",
       "      <td>45.615002</td>\n",
       "      <td>45.709999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12388</td>\n",
       "      <td>45.709000</td>\n",
       "      <td>45.719002</td>\n",
       "      <td>45.560001</td>\n",
       "      <td>45.629002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12389</td>\n",
       "      <td>45.632000</td>\n",
       "      <td>45.655998</td>\n",
       "      <td>45.474998</td>\n",
       "      <td>45.549999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12390</td>\n",
       "      <td>45.548000</td>\n",
       "      <td>45.612999</td>\n",
       "      <td>45.519001</td>\n",
       "      <td>45.548000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12391</td>\n",
       "      <td>45.549999</td>\n",
       "      <td>45.566002</td>\n",
       "      <td>45.449001</td>\n",
       "      <td>45.449001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9172</th>\n",
       "      <td>18890</td>\n",
       "      <td>73.696198</td>\n",
       "      <td>73.899597</td>\n",
       "      <td>73.607002</td>\n",
       "      <td>73.696098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9173</th>\n",
       "      <td>18891</td>\n",
       "      <td>73.659302</td>\n",
       "      <td>73.790100</td>\n",
       "      <td>73.549004</td>\n",
       "      <td>73.658997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9174</th>\n",
       "      <td>18892</td>\n",
       "      <td>73.795097</td>\n",
       "      <td>73.941498</td>\n",
       "      <td>73.650002</td>\n",
       "      <td>73.792702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9175</th>\n",
       "      <td>18893</td>\n",
       "      <td>73.875000</td>\n",
       "      <td>73.925797</td>\n",
       "      <td>73.588997</td>\n",
       "      <td>73.874901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9176</th>\n",
       "      <td>18894</td>\n",
       "      <td>73.839897</td>\n",
       "      <td>73.875198</td>\n",
       "      <td>73.621002</td>\n",
       "      <td>73.839996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4598 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date       open       high        low      close\n",
       "0     12387  45.709000  45.728001  45.615002  45.709999\n",
       "1     12388  45.709000  45.719002  45.560001  45.629002\n",
       "2     12389  45.632000  45.655998  45.474998  45.549999\n",
       "3     12390  45.548000  45.612999  45.519001  45.548000\n",
       "4     12391  45.549999  45.566002  45.449001  45.449001\n",
       "...     ...        ...        ...        ...        ...\n",
       "9172  18890  73.696198  73.899597  73.607002  73.696098\n",
       "9173  18891  73.659302  73.790100  73.549004  73.658997\n",
       "9174  18892  73.795097  73.941498  73.650002  73.792702\n",
       "9175  18893  73.875000  73.925797  73.588997  73.874901\n",
       "9176  18894  73.839897  73.875198  73.621002  73.839996\n",
       "\n",
       "[4598 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = merge(cleaned_forex_df, cleaned_usdinr_df)\n",
    "print('Merged the two datasets')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged and did the train/test split of the datasets\n"
     ]
    }
   ],
   "source": [
    "merged_x_train, merged_x_test, merged_y_train, merged_y_test = split(merged_df)\n",
    "print('Merged and did the train/test split of the datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3237.7278\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3229.9966\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3221.7520\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3213.0498\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3204.2971\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3194.2205\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3183.4172\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3173.5510\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3161.8787\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3149.5027\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 3215.9094\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3205.8025\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3197.4041\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3189.6904\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3183.7490\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3178.0327\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3172.7097\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3167.4148\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3161.6028\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3154.4670\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3285.1116\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3272.7239\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3260.6521\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3248.7979\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3239.0791\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3229.2236\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3218.1653\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3206.9753\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3193.7104\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3180.6675\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3275.3359\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3262.8650\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3251.7583\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3240.9373\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3229.8386\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3218.7925\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3207.7400\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3196.9160\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3185.4065\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3173.3118\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3262.1316\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3251.3374\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3240.7202\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3229.2620\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3217.8865\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3206.2810\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3194.3945\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3180.6804\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3166.9331\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3151.5120\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3241.2759\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3235.9075\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3233.5515\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3231.9099\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3229.8623\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3227.7258\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3225.5010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3222.6414\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3219.3994\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3215.8726\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3265.6257\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3255.9573\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3247.6711\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3241.5271\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3236.4666\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3231.4495\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3225.8040\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3220.2261\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3214.1990\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3207.2634\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 7s 7s/step - loss: 3282.3396\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3270.9641\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3257.8655\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3245.1860\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3231.4971\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3216.6721\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3202.9275\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3186.2615\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3169.5813\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3152.6621\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3260.8625\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3252.7563\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3246.9597\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3244.0820\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3241.2722\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3238.2034\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3234.7825\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3231.0142\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3226.7642\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3222.1357\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3245.8057\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3234.7942\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3223.7161\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3212.7937\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3200.8179\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3188.7617\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3175.5010\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3161.8242\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3147.2737\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3131.7471\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F745A0BF40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F746903A30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "%run lstm_rnn.py\n",
    "%run rand_network_ensemble.py\n",
    "\n",
    "lstm_args = { \n",
    "    \"input_shape\": (len(merged_x_train.to_numpy()), len(merged_x_train.to_numpy()[0])), \n",
    "    \"lstm_units\": 32, \n",
    "    \"dense_units\": 16, \n",
    "    \"output_shape\": (1,) \n",
    "}\n",
    "ensembler = RandomNetworkEnsemble(num_networks = 10, base_nn_model = CustomLSTM, model_args = lstm_args, random_seed = 522)\n",
    "\n",
    "ensembler.train(merged_x_train.to_numpy(), merged_y_train.to_numpy())\n",
    "predicted_target = ensembler.predict(merged_x_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of tuned model's predictions: 56.53793166476693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.05988596, 0.1086991 , 0.17072818, ..., 0.8531227 , 0.8531227 ,\n",
       "       0.8531227 ], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('RMSE of tuned model\\'s predictions: ' + str(ensembler.calculate_rmse_of_predicted(merged_y_test.to_numpy())))\n",
    "\n",
    "predicted_target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
